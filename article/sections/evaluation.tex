\section{Experimental Evaluation}

The objective of this section is to show that \toolname{} is capable of finding vulnerabilities in web applications written in different languages and that the effort needed to add a new language to the tool is relatively small. First, we present the results of analyzing several web applications in Java and PHP. Then, we discuss the effort needed to add support for another language.

\subsection{Taint analysis tests}
In order to show the ability of \toolname{} to analyze and find vulnerabilities in web applications, we tested \toolname{} against two types of web applications. First, we chose 5 open source applications from GitHub that are deliberately insecure, with documented vulnerabilities. The criteria used to choose them was the number of stars that each application has on GitHub, essentially choosing the most known ones. To run the tests, we had to manually identify the entry points and sensitive functions for each application, meaning that we analyzed each application several times, once for each entry point. Second, we also tested \toolname{} against some real-world open-source web applications. Since these applications are much bigger, we tested them automatically assuming that each file is an entry point and tainting the variables that might be influenced by the user (e.g., \$\_GET[*] in PHP). Tables \ref{results} and \ref{results1} show the results of our analysis. In the data, we only include files with the extension that we analyzed (e.g., *.java and *.php). Furthermore, we excluded comments and blank lines from the line count. 


\begin{table}[htbp]
    \caption{Deliberately insecure web applications}
    \begin{center}
        \begin{spreadtab}{{tabular}{|l|| l | l  |l | l |}}
            \hline
            @ \textbf{Application}  & @\textbf{\#loc}      & @\textbf{Language}      & @\textbf{Files}     & @\textbf{Vuln. Found } \\ [0.5ex] 
            \hline\hline   
            @ WebGoat 8             & 13898     & @ Java       & 320        & 11 \\
            \hline
            @ Vulnado               & 423       & @ Java       & 11         & 3 \\
            \hline
            @ Dvja                  & 950       & @ Java       & 21         & 4 \\
            \hline
            @  DVWA                 & 19651     & @ PHP        & 358        & 18 \\
            \hline
            @  OWASP Vwa            & 1018      & @ PHP        & 27         & 17 \\   
            \hline
            @  Vulnerable-node      & 4207      & @ JavaScript & 13         & 5 \\  
            \hline
            @  Dvna                 & 771      & @ JavaScript  & 14         & 0 \\
            \hline  
            @  Vulpy                 & 2373      & @ Python    & 57         & 6 \\
            \hline  
            @  Dvpwa                 & 674      & @ Python    & 21         & 7 \\   [0.5ex]  
            \hline\hline   
            @ \textbf{Total}        & sum(b2:b10) &              &  sum(d2:d10) &  sum(e2:e10) \\
            \hline
        \end{spreadtab}
    \label{results}
    \end{center}
\end{table}


\begin{table}[htbp]
    \caption{Real-world web applications}
    \begin{center}
        \begin{spreadtab}{{tabular}{|l|| l | l  |l | l |}}
            \hline
            @ \textbf{Application}  & @\textbf{\#loc}      & @\textbf{Language}      & @\textbf{Files}     & @\textbf{Vuln. Found } \\ [0.5ex] 
            \hline\hline   
            @  SquirrelMail 1.5     & 46214     & @ PHP        & 376         & 0 \\ 
            \hline
            @  PhpMyAdmin           & 224852    & @ PHP        & 728        & 0 \\  [0.5ex]    
            \hline\hline   
            @ \textbf{Total}        & sum(b2:b3) &              &  sum(d2:d3) &  sum(e2:e3) \\
            \hline
        \end{spreadtab}
    \label{results1}
    \end{center}
\end{table}


\toolname{} analyzed 1946 files and 315031 lines of code and managed to find 71 documented vulnerabilities, such as SQL injection, cross-site scripting, command injection and file inclusion. The analysis times were quite low. The application that took the longest to analyze was \textit{PhpMyAdmin} with 82 seconds. However, the analysis times varied a lot depending on the entry point, meaning that the longer the path through which the data flows, the longer the analysis time.

In our tests, the tool had 2 false negatives due to string interpolation in PHP. If we have a variable named "\$id", and then we have "echo "\$\{id\}";" \toolname{} does not understand that "id" is referring to variable "\$id", thus treating "id" as a constant.




\toolname{} did not raise any false positives in the applications from table \ref{results}, we may assume that this is due to our conservative taint analysis and to the relatively simple web applications that we have tested. We can not make any assertions about the false positives from the applications from table \ref{results1} since \toolname{} did not report any vulnerabilities and also, we are not aware of any existing vulnerabilities in the versions we tested.




\subsection{Portability}

Since the objective of this work is to support several languages with as little effort as possible, the portability of the tool is also a metric that we tested. To test the portability, we first implemented the tool to support PHP analysis, and then we added support for Java, which is a substantially different language. While adding support for PHP and Java we were also developing the other modules, so it is hard to tell how much time was spent strictly adding support for each language. However, later, after the tool was built, we added support for JavaScript and then Python and we spent roughly 7 hours adding each language. In our opinion, the main challenge when adding support for a new language is identifying which elements from the grammar are important to the analysis. After that, we just have to  write the converter and some unit tests to make sure the converter works properly.

Table \ref{converters} presents the order in which the languages were added, the number of lines of each converter, the number of unique statements and the number of hours spent developing each one of them.
The number of unique statements is meant to show that the converter does not have much logic, it basically consists of calls to the \astbuilder{}. For example, the converter for Java has 108 lines, 30 of which are repeated (e.g., \textit{exitStatementOrExpression()} is invoked 19 times), leaving us with 78 unique statements.

\begin{table}[htbp!]
    \caption{Converters size and implementation effort}
    \begin{center}
        \begin{tabular}{|c|l|l|l|l|}
           \hline
           \thead{Impl. \\ order} & \thead{Language} & \thead{\#loc} & \thead{Unique \\ statements} & \thead{Hours to \\ implement} \\ [0.5ex] 
           \hline\hline
          1 &  PHP & 67 & 49 & --\\

           \hline
           2 & Java & 108 & 78 & --\\
         
           \hline
          3 & JavaScript & 50 & 41 & 7 \\
           \hline
          4 &  Python & 61 & 49 & 7 \\
           \hline
          \end{tabular}
          \label{converters}
    \end{center}
    
\end{table}